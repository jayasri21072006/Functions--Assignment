{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0i47mvUI4S8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "051f4cff"
      },
      "source": [
        "**1. What is a parameter?**\n",
        "\n",
        "In the context of a machine learning model, a parameter is a configuration variable that is internal to the model and whose value is learned from the data. These are the values that the model adjusts during training to minimize the loss function and improve its performance. Examples include the weights and biases in a neural network, or the coefficients in a linear regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adba9a8b"
      },
      "source": [
        "**2. What is correlation?**\n",
        "\n",
        "Correlation is a statistical measure that describes the extent to which two variables are linearly related. It indicates how much two variables tend to change together. A positive correlation means that as one variable increases, the other tends to increase as well. A negative correlation means that as one variable increases, the other tends to decrease. A correlation close to zero suggests little to no linear relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0afe9acb"
      },
      "source": [
        "**3. What does negative correlation mean?**\n",
        "\n",
        "Negative correlation means that there is an inverse relationship between two variables. As the value of one variable increases, the value of the other variable tends to decrease. For example, there might be a negative correlation between the number of hours spent watching TV and a student's test scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b9e2d24"
      },
      "source": [
        "**4. Define Machine Learning. What are the main components in Machine Learning?**\n",
        "\n",
        "Machine Learning is a subfield of Artificial Intelligence that focuses on the development of algorithms that allow computers to learn from data and make predictions or decisions without being explicitly programmed.\n",
        "\n",
        "The main components in Machine Learning typically include:\n",
        "\n",
        "*   **Data:** The raw information used to train and evaluate the model.\n",
        "*   **Model:** The algorithm or mathematical structure that learns from the data.\n",
        "*   **Learning Algorithm:** The process used to train the model by adjusting its parameters based on the data.\n",
        "*   **Loss Function:** A function that measures how well the model is performing. The goal of training is to minimize this function.\n",
        "*   **Evaluation Metric:** A measure used to assess the model's performance on unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aacca50"
      },
      "source": [
        "**5. How does loss value help in determining whether the model is good or not?**\n",
        "\n",
        "The loss value quantifies the error of the model's predictions compared to the actual values. During training, the learning algorithm aims to minimize the loss function. A decreasing loss value over training iterations generally indicates that the model is learning and improving its ability to make accurate predictions. A low final loss value suggests that the model fits the training data well. However, a very low loss on the training data but high loss on unseen data might indicate overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e23363d4"
      },
      "source": [
        "**6. What are continuous and categorical variables?**\n",
        "\n",
        "*   **Continuous Variables:** These are variables that can take any value within a given range. They represent measurements and can have an infinite number of possible values between any two given values. Examples include height, weight, temperature, and time.\n",
        "*   **Categorical Variables:** These are variables that can take on a limited number of distinct values or categories. They represent qualities or characteristics and can be either nominal (categories with no inherent order, e.g., color, gender) or ordinal (categories with a natural order, e.g., education level, size)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b301b774"
      },
      "source": [
        "**7. How do we handle categorical variables in Machine Learning? What are the common techniques?**\n",
        "\n",
        "Machine learning algorithms typically work with numerical data, so categorical variables need to be converted into a numerical format. Common techniques include:\n",
        "\n",
        "*   **One-Hot Encoding:** Creates a new binary column for each category. A '1' in a column indicates the presence of that category, and '0' indicates its absence. This is suitable for nominal variables.\n",
        "*   **Label Encoding:** Assigns a unique integer to each category. This is suitable for ordinal variables where the integer value can reflect the order.\n",
        "*   **Ordinal Encoding:** Similar to label encoding but explicitly specifies the order of the categories.\n",
        "*   **Target Encoding:** Encodes categories based on the average of the target variable for each category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69ab9189"
      },
      "source": [
        "**8. What do you mean by training and testing a dataset?**\n",
        "\n",
        "*   **Training Dataset:** This is the portion of the dataset used to train the machine learning model. The model learns the patterns and relationships in the data from this set.\n",
        "*   **Testing Dataset:** This is the portion of the dataset used to evaluate the performance of the trained model on unseen data. It helps to assess how well the model generalizes to new data and to detect issues like overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1450939c"
      },
      "source": [
        "**9. What is sklearn.preprocessing?**\n",
        "\n",
        "`sklearn.preprocessing` is a module in the scikit-learn library that provides a collection of functions and classes to perform various data preprocessing tasks. These tasks include scaling, centering, normalizing, and encoding data, which are essential steps before training many machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ea3e9e6"
      },
      "source": [
        "**10. What is a Test set?**\n",
        "\n",
        "A test set is a subset of the original dataset that is held out during the training phase and is used to evaluate the performance of the trained machine learning model. It provides an unbiased assessment of the model's ability to generalize to new, unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a64bf86a"
      },
      "source": [
        "**11. How do we split data for model fitting (training and testing) in Python?**\n",
        "\n",
        "In Python, the `train_test_split` function from the `sklearn.model_selection` module is commonly used to split data into training and testing sets. You provide the features (X) and the target variable (y), and specify the proportion of data to be allocated to the testing set (e.g., `test_size=0.2` for 20%). You can also use `random_state` for reproducibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01c658e9"
      },
      "source": [
        "**12. How do you approach a Machine Learning problem?**\n",
        "\n",
        "A typical approach to a machine learning problem involves several steps:\n",
        "\n",
        "1.  **Problem Definition:** Clearly understand the problem you are trying to solve and the desired outcome.\n",
        "2.  **Data Collection:** Gather relevant data.\n",
        "3.  **Data Cleaning and Preprocessing:** Handle missing values, outliers, and transform data into a suitable format.\n",
        "4.  **Exploratory Data Analysis (EDA):** Understand the data's characteristics, identify patterns, and visualize relationships.\n",
        "5.  **Feature Engineering:** Create new features or modify existing ones to improve model performance.\n",
        "6.  **Model Selection:** Choose appropriate machine learning algorithms based on the problem type and data characteristics.\n",
        "7.  **Model Training:** Train the selected model on the training data.\n",
        "8.  **Model Evaluation:** Evaluate the model's performance on the test data using appropriate metrics.\n",
        "9.  **Hyperparameter Tuning:** Optimize the model's hyperparameters to improve performance.\n",
        "10. **Deployment (if applicable):** Deploy the trained model for making predictions on new data.\n",
        "11. **Monitoring and Maintenance:** Continuously monitor the model's performance and retrain or update it as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98323bb7"
      },
      "source": [
        "**13. Why do we have to perform EDA before fitting a model to the data?**\n",
        "\n",
        "EDA is crucial before model fitting for several reasons:\n",
        "\n",
        "*   **Understand the data:** Gain insights into the data's structure, distributions, and relationships between variables.\n",
        "*   **Identify patterns and trends:** Discover potential correlations, outliers, or anomalies that can inform feature engineering and model selection.\n",
        "*   **Assess data quality:** Identify missing values, inconsistencies, or errors that need to be addressed during preprocessing.\n",
        "*   **Inform feature selection:** Determine which features are most relevant to the problem and might be useful for the model.\n",
        "*   **Guide feature engineering:** Identify opportunities to create new features that could improve model performance.\n",
        "*   **Choose appropriate models:** Insights from EDA can help in selecting suitable machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c295b20"
      },
      "source": [
        "**14. What is correlation?**\n",
        "\n",
        "(Answered in question 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0f9cf8d"
      },
      "source": [
        "**15. What does negative correlation mean?**\n",
        "\n",
        "(Answered in question 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8543be4"
      },
      "source": [
        "**16. How can you find correlation between variables in Python?**\n",
        "\n",
        "In Python, you can calculate the correlation between variables using the `.corr()` method of a pandas DataFrame. This method computes the pairwise correlation of columns, excluding NA/null values. The default method is the Pearson correlation coefficient, which measures the linear relationship between two datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3d14078"
      },
      "source": [
        "**17. What is causation? Explain difference between correlation and causation with an example.**\n",
        "\n",
        "*   **Causation:** Causation means that one event is the direct result of another event. There is a cause-and-effect relationship.\n",
        "*   **Correlation:** Correlation indicates that two events or variables are related or tend to occur together, but it does not necessarily mean that one causes the other.\n",
        "\n",
        "**Difference and Example:**\n",
        "\n",
        "The key difference is that causation implies a direct influence, while correlation simply indicates an association.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "There is a strong positive correlation between ice cream sales and drowning incidents. As ice cream sales increase, the number of drowning incidents also tends to increase. However, this does not mean that eating ice cream causes drowning. The underlying cause for both is likely the warmer weather during summer, which leads to more people buying ice cream and more people swimming (and thus, unfortunately, more drowning incidents). This is an example of correlation without causation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54cc9798"
      },
      "source": [
        "**18. What is an Optimizer? What are different types of optimizers? Explain each with an example.**\n",
        "\n",
        "An optimizer is an algorithm used to minimize the loss function of a machine learning model during training. It adjusts the model's parameters iteratively to find the set of parameters that results in the lowest loss.\n",
        "\n",
        "Different types of optimizers include:\n",
        "\n",
        "*   **Gradient Descent (GD):** A basic optimizer that calculates the gradient of the loss function with respect to the model's parameters and updates the parameters in the opposite direction of the gradient.\n",
        "    *   **Example:** In a simple linear regression, GD would adjust the slope and intercept to minimize the difference between predicted and actual values.\n",
        "*   **Stochastic Gradient Descent (SGD):** A variation of GD that updates parameters using the gradient calculated from a single randomly selected training example at each iteration. This is faster for large datasets but can have noisy updates.\n",
        "    *   **Example:** Training a neural network on a large image dataset, SGD would update weights based on the error of one image at a time.\n",
        "*   **Mini-batch Gradient Descent:** A compromise between GD and SGD, it updates parameters using the gradient calculated from a small batch of training examples. This provides a balance between speed and stability.\n",
        "    *   **Example:** Training a neural network using batches of 32 or 64 images at each iteration.\n",
        "*   **Adam (Adaptive Moment Estimation):** A popular and often effective optimizer that uses adaptive learning rates for each parameter and incorporates momentum.\n",
        "    *   **Example:** Training a complex deep learning model where different parameters might require different learning rates.\n",
        "*   **RMSprop (Root Mean Square Propagation):** Another adaptive learning rate optimizer that divides the learning rate by the root mean square of past gradients.\n",
        "    *   **Example:** Similar to Adam, useful for training deep neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e56054b3"
      },
      "source": [
        "**19. What is sklearn.linear_model ?**\n",
        "\n",
        "`sklearn.linear_model` is a module in the scikit-learn library that provides a variety of linear models for regression and classification tasks. These models assume a linear relationship between the features and the target variable (or a linear transformation of it). Examples include `LinearRegression`, `LogisticRegression`, `Lasso`, and `Ridge`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8edc61f6"
      },
      "source": [
        "**20. What does model.fit() do? What arguments must be given?**\n",
        "\n",
        "The `model.fit()` method is used to train a machine learning model on the training data. It is where the learning process happens, and the model adjusts its internal parameters based on the provided data.\n",
        "\n",
        "The required arguments are:\n",
        "\n",
        "*   `X`: The training data features (a NumPy array or pandas DataFrame).\n",
        "*   `y`: The training data target variable (a NumPy array or pandas Series).\n",
        "\n",
        "Optional arguments might include `sample_weight` or `class_weight` depending on the specific model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d8671d2"
      },
      "source": [
        "**21. What does model.predict() do? What arguments must be given?**\n",
        "\n",
        "The `model.predict()` method is used to make predictions on new, unseen data using a trained machine learning model. It takes the input features and outputs the model's predicted values.\n",
        "\n",
        "The required argument is:\n",
        "\n",
        "*   `X`: The data for which you want to make predictions (a NumPy array or pandas DataFrame).\n",
        "\n",
        "The structure of `X` should be the same as the features used to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e9112da"
      },
      "source": [
        "**22. What are continuous and categorical variables?**\n",
        "\n",
        "(Answered in question 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5530dc5"
      },
      "source": [
        "**23. What is feature scaling? How does it help in Machine Learning?**\n",
        "\n",
        "Feature scaling is a data preprocessing technique used to standardize or normalize the range of independent variables (features) in a dataset. It involves transforming the values of features to a similar scale.\n",
        "\n",
        "How it helps:\n",
        "\n",
        "*   **Improves algorithm performance:** Many machine learning algorithms (like gradient descent-based methods, support vector machines, and k-nearest neighbors) are sensitive to the scale of features. Features with larger ranges can dominate those with smaller ranges, leading to biased results. Scaling ensures that all features contribute equally to the model's learning process.\n",
        "*   **Faster convergence:** For iterative optimization algorithms, scaling can help the algorithm converge faster to the optimal solution.\n",
        "*   **Avoids numerical instability:** Scaling can prevent numerical issues that might arise when dealing with very large or very small feature values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b593ef43"
      },
      "source": [
        "**24. How do we perform scaling in Python?**\n",
        "\n",
        "In Python, you can perform feature scaling using classes from the `sklearn.preprocessing` module. Common scalers include:\n",
        "\n",
        "*   **StandardScaler:** Standardizes features by removing the mean and scaling to unit variance.\n",
        "*   **MinMaxScaler:** Scales features to a given range (usually between 0 and 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e12608be"
      },
      "source": [
        "**25. Explain data encoding?**\n",
        "\n",
        "Data encoding is the process of converting data from one format to another. In machine learning, it often refers to the process of converting categorical variables into a numerical representation that can be used by algorithms. Since most machine learning algorithms require numerical input, encoding is a necessary step when dealing with categorical data. The techniques mentioned in question 7 (One-Hot Encoding, Label Encoding, etc.) are examples of data encoding methods used for categorical variables."
      ]
    }
  ]
}